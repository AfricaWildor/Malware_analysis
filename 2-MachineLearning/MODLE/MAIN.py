from model import *
import torchvision
import torchvision.transforms as transforms
from torch.autograd import Variable
import matplotlib.pyplot as plt
import torch
from torch.utils import data

plt_loss = []


def data_loader():

    # define method of preprocessing data for evaluating
    transform_train = transforms.Compose([
        transforms.Resize([256,256]),
        # transforms.RandomCrop(32),
        # transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        # Normalize a tensor image with mean and standard variance
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    ])

    transform_test = transforms.Compose([
        transforms.Resize([256,256]),
        # transforms.RandomCrop(32),
        transforms.ToTensor(),
        # Normalize a tensor image with mean and standard variance
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    ])

    # prepare dataset by ImageFolder, data should be classified by directory
    trainset = torchvision.datasets.ImageFolder(root='../../../imgs/grey/train', transform=transform_train)

    testset = torchvision.datasets.ImageFolder(root='../../../imgs/grey/test', transform=transform_test)

    # Data loader.
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True) #不同类别的图片将会打乱训练

    testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)
    return trainloader, testloader


def train(epoch, model, lossFunction, optimizer, device, trainloader): #一个epoch里面的训练过程
    """train model using loss_fn and optimizer. When this function is called, model trains for one epoch.
    Args:
        train_loader: train data
        model: prediction model
        loss_fn: loss function to judge the distance between target and outputs
        optimizer: optimize the loss function
        get_grad: True, False
    output:
        total_loss: loss
        average_grad2: average grad for hidden 2 in this epoch
        average_grad3: average grad for hidden 3 in this epoch
    """
    print('\nEpoch: %d' % epoch)
    model.train()  # enter train mode

    # 损失总数
    train_loss = 0
    # 正确率 = 正确个数 / 总个数
    correct = 0
    total = 0

    for batch_idx, (inputs, targets) in enumerate(trainloader):

        inputs, targets = inputs.to(device), targets.to(device)
        inputs, targets = Variable(inputs), Variable(targets)

        optimizer.zero_grad() # 不清零 将会梯度累计

        # print(inputs.shape)

        outputs = model(inputs)

        loss = lossFunction(outputs, targets) # 定义损失函数
        loss.backward() #求导
        optimizer.step() #参数更新

        train_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item() #计算预测准确率的指标

        # if (batch_idx + 1) % 100 == 0:
        #     # print loss and acc
        #     print('***Train loss: %.3f | Train Acc: %.3f%% (%d/%d)'
        #           % (train_loss / (batch_idx + 1), 100. * correct / total, correct, total))
    plt_loss.append(train_loss)
    print('Train loss: %.3f | Train Acc: %.3f%% (%d/%d)'
          % (train_loss / (batch_idx + 1), 100. * correct / total, correct, total))


def eval(model, lossFunction, optimizer, device, testloader):
    """
    test model's prediction performance on loader.
    When third function is called, model is evaluated.
    Args:
        loader: data for evaluation
        model: prediction model
        loss_fn: loss function to judge the distance between target and outputs
    output:
        total_loss
        accuracy
    """
    global best_acc
    model.eval()  # enter test mode
    test_loss = 0  # accumulate every batch loss in a epoch
    correct = 0
    total = 0
    with torch.no_grad():
        for batch_idx, (inputs, targets) in enumerate(testloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = lossFunction(outputs, targets)  # compute loss

            test_loss += loss.item()  # accumulate every batch loss in a epoch
            _, predicted = outputs.max(1)  # make prediction according to the outputs
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()  # count how many predictions is correct
        # print loss and acc
        print('Test Loss: %.3f  | Test Acc: %.3f%% (%d/%d)'
              % (test_loss / (batch_idx + 1), 100. * correct / total, correct, total))


def run(model, num_epochs):
    # load model into GPU device
    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
    # device = 'cpu'
    model.to(device)
    #     if device == 'cuda:0':
    #         model = torch.nn.DataParallel(model)
    #         cudnn.benchmark = True

    # define the loss function and optimizer

    lossFunction = nn.CrossEntropyLoss() #交叉熵函数
    lr = 0.01  # learningrate

    # 优化器
    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)

    trainloader, testloader = data_loader() # 数据集加载
    for epoch in range(num_epochs): #训练的轮数
        train(epoch, model, lossFunction, optimizer, device, trainloader)
        eval(model, lossFunction, optimizer, device, testloader)
        if (epoch + 1) % 50 == 0: #学习率调整
            lr = lr / 10
            for param_group in optimizer.param_groups:
                param_group['lr'] = lr

    fig = plt.figure()
    plt.plot(plt_loss, c='r')
    plt.show()


if __name__ == '__main__':
    # start training and testing
    model = densenet()
    # num_epochs is adjustable
    run(model, num_epochs=10)